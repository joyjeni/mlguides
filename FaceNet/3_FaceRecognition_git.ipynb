{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_FaceRecognition_git.ipynb","provenance":[],"authorship_tag":"ABX9TyO3uVT0VIun1WPbgLCKZ+Lq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"GmlJdOS4OsvA","executionInfo":{"status":"error","timestamp":1604039606430,"user_tz":-330,"elapsed":2060,"user":{"displayName":"Jenisha T","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqzVKuzMg4uiBHhOsZKcKKjc0ELvpGLp3eLRCHig=s64","userId":"08887085926348470121"}},"outputId":"4673101c-e449-4cd7-87a6-a9058b41b478","colab":{"base_uri":"https://localhost:8080/","height":758}},"source":["# Mount drive\n","from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)\n","\n","import os\n","os.chdir('./drive/My Drive/pluralsight_guides/facenet/FaceRecognition/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Mounted at /content/drive\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-19-4e261a52b104>\", line 6, in <module>\n","    os.chdir('./drive/My Drive/pluralsight_guides/facenet/FaceRecognition/')\n","OSError: [Errno 107] Transport endpoint is not connected: './drive/My Drive/pluralsight_guides/facenet/FaceRecognition/'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n","    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n","  File \"/usr/lib/python3.6/inspect.py\", line 725, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.6/inspect.py\", line 709, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.6/posixpath.py\", line 383, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n"],"name":"stdout"},{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"]}]},{"cell_type":"code","metadata":{"id":"ltG5vlNiO4H2"},"source":["import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uZ-9lIm5PmB1"},"source":["!pip install mtcnn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iKr8tgl2PeWw"},"source":["import mtcnn\n","# print version\n","print(mtcnn.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oL6nj3U1Peau"},"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import cv2 # opencv\n","from mtcnn.mtcnn import MTCNN\n","from matplotlib import pyplot as plt\n","from keras.models import load_model\n","from PIL import Image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J9FBiQbzQqb_"},"source":["!pwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hhO0Lb6IPehv"},"source":["import os\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BUcTkj2ZXw8t"},"source":["!pwd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_nvu2EcuQzeP"},"source":["See sample image"]},{"cell_type":"code","metadata":{"id":"oGd6Ant8Q1Xk"},"source":["\n","img = cv2.imread('ur/img/path.jpg')\n","print(img)\n","plt.imshow(img)\n","plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n","plt.show()\n","print(img.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"am6v6fxrYMxv"},"source":["def extract_face(filename, required_size=(160, 160)):\n","    # load image from file\n","    image = Image.open(filename)\n","    # convert to RGB, if needed\n","    image = image.convert('RGB')\n","    # convert to array\n","    pixels = np.asarray(image)\n","    # create the detector, using default weights\n","    detector = MTCNN()\n","    # detect faces in the image\n","    results = detector.detect_faces(pixels)\n","    # extract the bounding box from the first face\n","    x1, y1, width, height = results[0]['box']\n","    # deal with negative pixel index\n","    x1, y1 = abs(x1), abs(y1)\n","    x2, y2 = x1 + width, y1 + height\n","    # extract the face\n","    face = pixels[y1:y2, x1:x2]\n","    # resize pixels to the model size\n","    image = Image.fromarray(face)\n","    image = image.resize(required_size)\n","    face_array = np.asarray(image)\n","    return face_array\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FlPcl8j5YO69"},"source":["# load the photo and extract the face\n","pixels = extract_face('./images1/train/Sundar_Pichai/Sundar_Pichai_1.jpg')\n","plt.imshow(pixels)\n","plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n","plt.show()\n","print(img.shape)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BMASODazYcTw"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SZQhUrQJYdPP"},"source":["Apply extract_face() for all faces in the dataset"]},{"cell_type":"code","metadata":{"id":"PWcggG8OYiLZ"},"source":["def load_face(dir):\n","  \n","  faces = list()\n","  # enumerate files\n","  for filename in os.listdir(dir):\n","      path = dir + filename\n","      print(path)        \n","      face = extract_face(path)\n","      faces.append(face)\n","  return faces\n","                \n","def load_dataset(dir):\n","    count =0\n","\n","    # list for faces and labels\n","    X, y = list(), list()\n","    for subdir in os.listdir(dir):\n","      try:\n","        path = dir + subdir + '/'\n","        faces = load_face(path)\n","        labels = [subdir for i in range(len(faces))]\n","        print(\"loaded %d sample for class: %s\" % (len(faces),subdir) ) # print progress\n","        X.extend(faces)\n","        y.extend(labels)  \n","        #print(faces.shape)          \n","\n","      except IndexError:\n","        print(\"Index Error\")\n","        print(subdir)\n","        count=count+1\n","        print(count)\n","      continue\n","\n","    return np.asarray(X), np.asarray(y)  \n","\n","# load train dataset\n","trainX, trainy = load_dataset('./input1/train/')\n","print(trainX.shape, trainy.shape)\n","# load test dataset\n","testX, testy = load_dataset('./input1/val/')\n","print(testX.shape, testy.shape)\n","\n","# save and compress the dataset for further use\n","np.savez_compressed('5-faces-dataset.npz', trainX, trainy, testX, testy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H08nsGNvZehg"},"source":["# load the face dataset\n","data = np.load('5-faces-dataset.npz')\n","trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n","print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ja2mwkVkZi0w"},"source":["# load the facenet model\n","facenet_model = load_model('./models/facenet_keras.h5')\n","print('Loaded Model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CagEYK5sZjGG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vpF-sk78aMA7"},"source":["Standardizing the faces and extracting a embedding vector using the model"]},{"cell_type":"code","metadata":{"id":"OC6nK7YeaOKd"},"source":["def get_embedding(model, face):\n","    # scale pixel values\n","    face = face.astype('float32')\n","    # standardization\n","    mean, std = face.mean(), face.std()\n","    face = (face-mean)/std\n","    # transfer face into one sample (3 dimension to 4 dimension)\n","    sample = np.expand_dims(face, axis=0)\n","    print(\"sample\",sample)\n","    # make prediction to get embedding\n","    yhat = model.predict(sample)\n","    \n","    return yhat[0]\n","    \n","# convert each face in the train set into embedding\n","emdTrainX = list()\n","for face in trainX:\n","    emd = get_embedding(facenet_model, face)\n","    emdTrainX.append(emd)\n","    \n","emdTrainX = np.asarray(emdTrainX)\n","print(emdTrainX.shape)\n","\n","# convert each face in the test set into embedding\n","emdTestX = list()\n","for face in testX:\n","    emd = get_embedding(facenet_model, face)\n","    emdTestX.append(emd)\n","emdTestX = np.asarray(emdTestX)\n","print(emdTestX.shape)\n","\n","# save arrays to one file in compressed format\n","np.savez_compressed('5-faces-embeddings.npz', emdTrainX, trainy, emdTestX, testy)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u0ZCM6nCaYHE"},"source":["from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import Normalizer\n","from sklearn.svm import SVC\n","\n","print(\"Dataset: train=%d, test=%d\" % (emdTrainX.shape[0], emdTestX.shape[0]))\n","# normalize input vectors\n","in_encoder = Normalizer()\n","emdTrainX_norm = in_encoder.transform(emdTrainX)\n","emdTestX_norm = in_encoder.transform(emdTestX)\n","# label encode targets\n","out_encoder = LabelEncoder()\n","out_encoder.fit(trainy)\n","trainy_enc = out_encoder.transform(trainy)\n","testy_enc = out_encoder.transform(testy)\n","# fit model\n","model = SVC(kernel='linear', probability=True)\n","model.fit(emdTrainX_norm, trainy_enc) \n","# predict\n","yhat_train = model.predict(emdTrainX_norm)\n","yhat_test = model.predict(emdTestX_norm)\n","# score\n","score_train = accuracy_score(trainy_enc, yhat_train)\n","score_test = accuracy_score(testy_enc, yhat_test)\n","# summarize\n","print('Accuracy: train=%.3f, test=%.3f' % (score_train*100, score_test*100))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XFfpUO9oaYra"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OBF9TIO8akFa"},"source":["Randomly select a face from test set for prediction. Calculate confidence"]},{"cell_type":"code","metadata":{"id":"qbMsqei2aYEY"},"source":["from random import choice\n","# select a random face from test set\n","selection = choice([i for i in range(testX.shape[0])])\n","random_face = testX[selection]\n","random_face_emd = emdTestX_norm[selection]\n","random_face_class = testy_enc[selection]\n","random_face_name = out_encoder.inverse_transform([random_face_class])\n","\n","# prediction for the face\n","samples = np.expand_dims(random_face_emd, axis=0)\n","yhat_class = model.predict(samples)\n","yhat_prob = model.predict_proba(samples)\n","# get name\n","class_index = yhat_class[0]\n","class_probability = yhat_prob[0,class_index] * 100\n","predict_names = out_encoder.inverse_transform(yhat_class)\n","all_names = out_encoder.inverse_transform([0,1])\n","#print('Predicted: %s (%.3f)' % (predict_names[0], class_probability))\n","print('Predicted: \\n%s \\n%s' % (all_names, yhat_prob[0]*100))\n","print('Expected: %s' % random_face_name[0])\n","# plot face\n","plt.imshow(random_face)\n","title = '%s (%.3f)' % (predict_names[0], class_probability)\n","plt.title(title)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ogGP436VH0qT"},"source":[""],"execution_count":null,"outputs":[]}]}